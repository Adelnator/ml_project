{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Импорты и инициализации #\n",
    "###########################\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utilsscx\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# Задаем seed для повторяемости результатов\n",
    "np.random.seed(42)\n",
    "\n",
    "# image_width = 168\n",
    "# image_height = 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Масштабируем изображения к одному размеру #\n",
    "#############################################\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk('train_data'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.bmp'):\n",
    "            img = cv2.imread(os.sep.join([dirpath, filename]))\n",
    "            res = cv2.resize(img, (32, 32), interpolation = cv2.INTER_CUBIC)\n",
    "            cv2.imwrite(os.sep.join([dirpath, filename[5:]]), res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Считываем данные и подготавливаем их к обучению #\n",
    "###################################################\n",
    "\n",
    "list_of_files = []\n",
    "target = []\n",
    "i = -1\n",
    "mapa = {}\n",
    "for (dirpath, dirnames, filenames) in os.walk('Dataset_new/train_data'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.bmp'):\n",
    "            target.append(i)\n",
    "            list_of_files.append(os.sep.join([dirpath, filename]))\n",
    "    mapa[i] = dirpath\n",
    "    i += 1\n",
    "print(mapa)\n",
    "data = []\n",
    "flag = True\n",
    "for file_name in list_of_files:\n",
    "#     data.append(cv2.imread(file_name))\n",
    "    img = image.load_img(file_name, target_size = (128, 128), grayscale = True)\n",
    "#     t = img[72:240, 40:208]\n",
    "    tmp = image.img_to_array(img)\n",
    "#     t = tmp[72:240, 40:208]\n",
    "    tmp /= 255\n",
    "    data.append(tmp)\n",
    "#     if (flag):\n",
    "#         train_data = np.array(tmp)\n",
    "#         flag = False\n",
    "#     else:\n",
    "#         np.append(train_data, tmp, axis = 1)\n",
    "#         print(train_data.shape)\n",
    "#     train_data.append(tmp)\n",
    "#     np.append(train_data_2, tmp, axis = 0)\n",
    "\n",
    "train_data = np.array(data)\n",
    "# for i, item in enumerate(train_data):\n",
    "#     t = item[72:240, 40:208]\n",
    "#     train_data[i] = t\n",
    "train_target = np_utils.to_categorical(target, 4)\n",
    "# train_target.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Создаем и обучаем модель 1 #\n",
    "##############################\n",
    "\n",
    "# Создаем модель\n",
    "model = Sequential()\n",
    "\n",
    "# ПЕРВЫЙ КАСКАД СЕТИ\n",
    "# Первый сверточный слой\n",
    "model.add(Convolution2D(32, 5, 5,\n",
    "                 padding = 'same',\n",
    "                 input_shape = (1, 60, 77),\n",
    "                 activation = 'relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Convolution2D(32, 5, 5, activation = 'relu'))\n",
    "# Слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), dim_ordering=\"tf\"))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.25))\n",
    "# ВТОРОЙ КАСКАД СЕТИ\n",
    "# Третий сверточный слой\n",
    "model.add(Convolution2D(64, 5, 5,\n",
    "                 padding = 'same',\n",
    "                 activation = 'relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Convolution2D(64, 5, 5, activation = 'relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), dim_ordering=\"tf\"))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# КЛАССИФИКАТОР\n",
    "# Преобразование из двумерного вида в плоский\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной слой\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "# КОМПИЛЯЦИЯ СЕТИ\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'SGD',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# ОБУЧЕНИЕ СЕТИ\n",
    "model.fit(train_data, train_target,\n",
    "          batch_size = 32,\n",
    "          epochs = 25,\n",
    "          validation_split = 0.1,\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# Создаем и обучаем модель 2 #\n",
    "##############################\n",
    "\n",
    "# Создаем последовательную сеть\n",
    "model = Sequential()\n",
    "\n",
    "# КАСКАД СВЕРТОК\n",
    "# Первый сверточный слой\n",
    "model.add(Convolution2D(75, 5, 5,\n",
    "                 padding = 'valid',\n",
    "                 input_shape = (1, 32, 32)))\n",
    "model.add(Activation('relu'))\n",
    "# Слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.2))\n",
    "# Второй сверточный слой\n",
    "model.add(Convolution2D(100, 5, 5,\n",
    "                 activation = 'relu'))\n",
    "model.add(Activation('relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), dim_ordering=\"tf\"))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# КЛАССИФИКАТОР\n",
    "# Преобразование из двумерного вида в плоский\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной слой\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# КОМПИЛЯЦИЯ СЕТИ\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# ОБУЧЕНИЕ СЕТИ\n",
    "model.fit(train_data, train_target,\n",
    "          batch_size = 32,\n",
    "          epochs = 25,\n",
    "          validation_split = 0.2,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# Сохранение сети #\n",
    "###################\n",
    "\n",
    "# model_json = model.to_json()\n",
    "# json_file = open('model.json', 'w')\n",
    "# json_file.write(model_json)\n",
    "# json_file.close()\n",
    "# model.save_weights('model.h5')\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Загрузка сети #\n",
    "#################\n",
    "\n",
    "from keras.models import load_model, model_from_json\n",
    "\n",
    "# json_file = open('model.json', 'r')\n",
    "# loadedmodel_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# loaded_model.load_weight('model.h5')\n",
    "\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Подготовка тестовых данных и проверка сети на них #\n",
    "#####################################################\n",
    "\n",
    "list_of_files = []\n",
    "target = []\n",
    "i = -1\n",
    "mapa = {}\n",
    "for (dirpath, dirnames, filenames) in os.walk('Dataset_new/test_data/test_data'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.bmp'):\n",
    "            target.append(i)\n",
    "            list_of_files.append(os.sep.join([dirpath, filename]))\n",
    "    mapa[i] = dirpath\n",
    "    i += 1\n",
    "print(mapa)\n",
    "\n",
    "data = []\n",
    "for file_name in list_of_files:\n",
    "    img = image.load_img(file_name, target_size = (128, 128), grayscale = True)\n",
    "    tmp = image.img_to_array(img)\n",
    "    tmp /= 255\n",
    "    data.append(tmp)\n",
    "\n",
    "test_data = np.array(data)\n",
    "test_target = np_utils.to_categorical(target, 4)\n",
    "\n",
    "# Проверяем точность модели на тестовых данных\n",
    "scores = model.evaluate(test_data, test_target, verbose = 0)\n",
    "\n",
    "# Печатаем точность\n",
    "print(\"Точность работы на тестовых данных: %.2f%%\" %(scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# Создаем и обучаем модель 3 #\n",
    "##############################\n",
    "\n",
    "# Создаем модель\n",
    "model = Sequential()\n",
    "\n",
    "# ПЕРВЫЙ КАСКАД СЕТИ\n",
    "# Первый сверточный слой\n",
    "model.add(Convolution2D(32, 3, 3,\n",
    "                          border_mode = 'same',\n",
    "                          input_shape = (32, 32, 3),\n",
    "                          activation = 'relu'))\n",
    "# Второй сверточный слой\n",
    "model.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "# Слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), dim_ordering=\"tf\"))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# ВТОРОЙ КАСКАД СЕТИ\n",
    "# Третий сверточный слой\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                       border_mode = 'same',\n",
    "                       activation = 'relu'))\n",
    "# Четвертый сверточный слой\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "                        border_mode = 'same',\n",
    "                        activation = 'relu'))\n",
    "# Второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), dim_ordering=\"tf\"))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# КЛАССИФИКАТОР\n",
    "# Преобразование из двумерного вида в плоский\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "# Слой регуляризации\n",
    "model.add(Dropout(0.5))\n",
    "# Выходной слой\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "# КОМПИЛЯЦИЯ СЕТИ\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'SGD',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "# ОБУЧЕНИЕ СЕТИ\n",
    "model.fit(train_data, train_target,\n",
    "         batch_size = 32,\n",
    "         nb_epoch = 25,\n",
    "         validation_split = 0.1,\n",
    "         shuffle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
